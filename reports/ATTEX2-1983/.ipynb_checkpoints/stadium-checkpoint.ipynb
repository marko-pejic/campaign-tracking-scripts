{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499439d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pyathena import connect\n",
    "from pyathena.pandas.util import as_pandas\n",
    "from pyathena.pandas.cursor import PandasCursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1a92c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load client data\n",
    "client = \"stadium\"\n",
    "client_df = pd.read_excel(f\"./{client}_input_data.xlsx\", converters={\"Imps\": int, \"Placement Id\": int})\n",
    "client_df[\"Viewability Rate %\"] = client_df[\"Viewability Rate %\"].str.replace(\",\", \".\").astype(float)\n",
    "client_placement_ids = list(client_df[\"Placement Id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd22dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch impressions using PyAthena library\n",
    "cursor = connect(s3_staging_dir=\"s3://aws-athena-query-results-094611745175-eu-west-1/\",\n",
    "                 region_name=\"eu-west-1\", profile_name=\"atexprodadminsso\", cursor_class=PandasCursor).cursor()\n",
    "\n",
    "impressions_df = cursor.execute(f'''\n",
    "select \n",
    "    \"impression_model\".\"id\", \n",
    "    \"hostname\", \n",
    "    \"placement_ids\", \n",
    "    \"placement_ids_chosen\", \n",
    "    \"total_fixation_duration\", \n",
    "    \"channel\", \n",
    "    \"ad_technical_format\", \n",
    "    \"is_fixated\", \n",
    "    \"gaze_valid\", \n",
    "    \"is_iab_inview\", \n",
    "    \"exist_viewable_1_s_threshold_50\", \n",
    "    \"exist_viewable_2_s_threshold_50\", \n",
    "    \"impression_model\".\"part_month\", \n",
    "    CONCAT(cast(\"ad_width_chosen\" as VARCHAR), 'x', cast(\"ad_width_chosen\" as VARCHAR)) as size,\n",
    "    \"stadium\".\"chosen_brand\" as \"chosen_brand\"\n",
    "from \"prod_attentionpanel_com_eu_west_1\".\"impression_model\"\n",
    "join \"groupm-brand-batch\".\"stadium\" on impression_model.id = stadium.id\n",
    "where impression_model.part_year = '2023'\n",
    "''').as_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a21b2ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7510/3375560408.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  impressions_df['pid'] = impressions_df['pid'].apply(lambda pid: int(pid))\n"
     ]
    }
   ],
   "source": [
    "def extract_pid(placement_id):\n",
    "    placement_id = json.loads(placement_id)\n",
    "    bam_ad_slots = placement_id[\"bam_ad_slot\"]\n",
    "    final_bam_ad_slots = [bas for bas in bam_ad_slots if bas.strip() != '']\n",
    "    try:\n",
    "        ret = placement_id['tag_id'][0]\n",
    "    except:\n",
    "        return\n",
    "    ret += ','.join([bas for bas in final_bam_ad_slots])\n",
    "    return ret\n",
    "\n",
    "def pid_type(pid):\n",
    "    try:\n",
    "        int(pid)\n",
    "        return 'int'\n",
    "    except:\n",
    "        return 'str'\n",
    "\n",
    "impressions_df['pid'] = impressions_df['placement_ids'].apply(extract_pid)\n",
    "impressions_df['pid_type'] = impressions_df['pid'].apply(pid_type)\n",
    "impressions_df = impressions_df[impressions_df[\"pid_type\"] == 'int']\n",
    "impressions_df['pid'] = impressions_df['pid'].apply(lambda pid: int(pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cf9577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get local predictions and store them in a map\n",
    "def _get_pred_map():\n",
    "    pred_map = dict()\n",
    "    _year = 2023\n",
    "    _range1 = 1\n",
    "    _range2 = 11\n",
    "    for i in range(_range1, _range2):\n",
    "        if i < 10:\n",
    "            i = f'0{i}'\n",
    "        for day in os.listdir(f'../../predictions/{_year}/{i}'):\n",
    "            for h in os.listdir(f'../../predictions/{_year}/{i}/{day}'):\n",
    "                if not h.endswith('.ndjson'):\n",
    "                    continue\n",
    "                with open(f'../../predictions/{_year}/{i}/{day}/{h}')as f:\n",
    "                    for line in f.readlines():\n",
    "                        json_line = json.loads(line)\n",
    "                        id_ = json_line['id']\n",
    "                        pred_map[id_] = json_line['prediction']\n",
    "    return pred_map\n",
    "                            \n",
    "pred_map = _get_pred_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5ea2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter impressions based on tier\n",
    "### TIER 1 ###\n",
    "# This is the most accurate data we have. This is \"campaign data\", meaning correct brand and timeframe\n",
    "### TIER 2 ###\n",
    "# We might not have enough campaign data (tier 1). Tier 2 data is brand data, for a longer period (roughly 6 months)\n",
    "### TIER 3 ###\n",
    "# This is the least accurate data for a campaign. It ignore brand/timeframe and only checks Placement ID. This is mostly used as a benchmark\n",
    "tier = 1\n",
    "filtered_impressions = impressions_df[impressions_df[\"pid\"].isin(client_placement_ids)]\n",
    "if tier == 1:\n",
    "    filtered_impressions = filtered_impressions[filtered_impressions[\"part_month\"] == \"10\"]\n",
    "if tier < 3:\n",
    "    filtered_impressions = filtered_impressions[filtered_impressions[\"chosen_brand\"] == client.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2802282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_final_fixation(gaze_valid, is_fixated, id_, pred_map):\n",
    "    if gaze_valid:\n",
    "        return is_fixated\n",
    "    if id_ in pred_map:\n",
    "        return pred_map[id_]\n",
    "    return False\n",
    "\n",
    "filtered_impressions['final_fixation'] = filtered_impressions.apply(lambda row: _get_final_fixation(row['gaze_valid'], row['is_fixated'], row['id'], pred_map), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ae3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_impressions[\"true_is_iab_inview\"] = filtered_impressions.apply(\n",
    "    lambda x: \n",
    "    True if (\n",
    "        (x[\"ad_technical_format\"] == \"out-stream\") & (x[\"exist_viewable_1_s_threshold_50\"] == True) & (x[\"exist_viewable_2_s_threshold_50\"] == False)\n",
    "    ) | (x[\"is_iab_inview\"] == True) \n",
    "    else False, \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d20159",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_impressions[\"total_fixation_duration\"] = filtered_impressions[\"total_fixation_duration\"].astype(\"Int64\")\n",
    "# Normalise outliers for fixation duration (30 seconds)\n",
    "filtered_impressions.loc[filtered_impressions[\"total_fixation_duration\"] >= 30000, \"total_fixation_duration\"] = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab53591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions do not include fixation duration. For predicted fixations, use the median value as the total_fixation_duration\n",
    "\n",
    "# Calculate the median fixation duration for each hostname\n",
    "median_fixation_durations = filtered_impressions.loc[filtered_impressions['is_fixated'] == True].groupby('hostname')['total_fixation_duration'].median()\n",
    "\n",
    "# Update the total_fixation_duration based on the calculated medians\n",
    "filtered_impressions['total_fixation_duration'] = np.where(\n",
    "    (filtered_impressions['total_fixation_duration'] == 0) &\n",
    "    (filtered_impressions['final_fixation'] == True) &\n",
    "    (filtered_impressions['hostname'].isin(median_fixation_durations.index)),\n",
    "    filtered_impressions['hostname'].map(median_fixation_durations),\n",
    "    filtered_impressions['total_fixation_duration']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c84b589e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7510/325538934.py:1: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  grouped_df = filtered_impressions.groupby([\"pid\", \"hostname\"]).apply(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert hostname, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m filtered_impressions\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhostname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[1;32m      3\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:6361\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6355\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6356\u001b[0m             \u001b[38;5;66;03m# if we have the codes, extract the values with a mask\u001b[39;00m\n\u001b[1;32m   6357\u001b[0m             level_values \u001b[38;5;241m=\u001b[39m algorithms\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   6358\u001b[0m                 level_values, lab, allow_fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value\u001b[38;5;241m=\u001b[39mlev\u001b[38;5;241m.\u001b[39m_na_value\n\u001b[1;32m   6359\u001b[0m             )\n\u001b[0;32m-> 6361\u001b[0m         \u001b[43mnew_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6362\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlevel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_duplicates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_duplicates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6366\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6368\u001b[0m new_obj\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m new_index\n\u001b[1;32m   6369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4817\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4811\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_duplicates=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.flags.allows_duplicate_labels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;129;01mand\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   4816\u001b[0m     \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n\u001b[0;32m-> 4817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot insert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   4819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc must be int\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert hostname, already exists"
     ]
    }
   ],
   "source": [
    "grouped_df = filtered_impressions.groupby([\"pid\", \"hostname\"]).apply(\n",
    "    lambda x: pd.Series(\n",
    "        {\n",
    "            \"impressions\": x[\"id\"].count(),\n",
    "            \"fixations\": x.loc[x[\"final_fixation\"], \"id\"].count(),\n",
    "            \"inview\": x.loc[x[\"true_is_iab_inview\"], \"id\"].count(),\n",
    "            \"total_fixation_duration\": x[\"total_fixation_duration\"].sum(),\n",
    "            \"average_fixation_duration\": x[\"total_fixation_duration\"].mean()\n",
    "        }\n",
    "    )\n",
    ")\n",
    "grouped_df = grouped_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5513f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_client = client_df.groupby([\"Placement Id\"]).apply(\n",
    "    lambda x: pd.Series(\n",
    "        {\n",
    "            \"Imps\": x[\"Imps\"].sum(),\n",
    "            \"Viewability Rate %\": np.average(x[\"Viewability Rate %\"], weights=x[\"Imps\"])\n",
    "        }\n",
    "    )\n",
    ")\n",
    "grouped_client = grouped_client.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4572ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = grouped_df.merge(grouped_client, how=\"inner\", left_on=\"pid\", right_on=\"Placement Id\")\n",
    "merged_df = merged_df[[\"hostname\", \"Placement Id\", \"impressions\", \"fixations\", \"inview\", \"Imps\", \"Viewability Rate %\", \"average_fixation_duration\", \"total_fixation_duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386805d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_group = merged_df.groupby([\"hostname\"]).apply(\n",
    "     lambda x: pd.Series(\n",
    "         {\n",
    "             \"tobii_imps\": x[\"impressions\"].sum(),\n",
    "             \"client_imps\": x[\"Imps\"].sum(),\n",
    "             \"tobii_fixations\": x[\"fixations\"].sum(),\n",
    "             \"tobii_inview\": x[\"inview\"].sum(),\n",
    "             \"client_viewability_rate\": np.average(x[\"Viewability Rate %\"], weights=x[\"Imps\"]),\n",
    "             \"average_fixation_duration\": round(x[\"total_fixation_duration\"].sum() / x[\"fixations\"].sum(), 2),             \n",
    "             \"total_fixation_duration\": x[\"total_fixation_duration\"].sum()\n",
    "         }\n",
    "     )\n",
    ")\n",
    "final_group = final_group.reset_index()\n",
    "final_group[\"tobii_imps\"] = final_group[\"tobii_imps\"].astype(\"Int64\")\n",
    "final_group[\"client_imps\"] = final_group[\"client_imps\"].astype(\"Int64\")\n",
    "final_group[\"tobii_fixations\"] = final_group[\"tobii_fixations\"].astype(\"Int64\")\n",
    "final_group[\"tobii_inview\"] = final_group[\"tobii_inview\"].astype(\"Int64\")\n",
    "final_group[\"tobii_inview/impression_ratio\"] = round(final_group[\"tobii_inview\"] / final_group[\"tobii_imps\"] * 100, 2)\n",
    "final_group[\"tobii_fixation/impression_ratio\"] = round(final_group[\"tobii_fixations\"] / final_group[\"tobii_imps\"] * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d692a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_group[\"client_inview\"] = np.round(final_group[\"client_imps\"] * final_group[\"client_viewability_rate\"]).astype(\"Int64\")\n",
    "final_group[\"client_fixations\"] = np.round((final_group[\"tobii_fixations\"] / final_group[\"tobii_imps\"]) * final_group[\"client_imps\"]).astype(\"Int64\")\n",
    "final_group[\"client_fix/inview_ratio\"] = round(final_group[\"client_fixations\"] / final_group[\"client_inview\"] * 100, 2)\n",
    "final_group[\"client_total_fixation_duration\"] = final_group[\"client_fixations\"] * final_group[\"average_fixation_duration\"]\n",
    "\n",
    "def get_sample_size(num_impressions):\n",
    "    if num_impressions <= 99:\n",
    "        return \"low\"\n",
    "    elif num_impressions >= 100 and num_impressions <= 199:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "final_group[\"sample_size\"] = final_group[\"tobii_imps\"].apply(lambda x: get_sample_size(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe13902",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb7b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = final_group[[\"hostname\", \"tobii_imps\", \"client_imps\", \"tobii_fixations\", \"client_fixations\", \"tobii_inview\", \"client_inview\", \"client_fix/inview_ratio\", \"tobii_inview/impression_ratio\", \"client_viewability_rate\", \"tobii_fixation/impression_ratio\", \"average_fixation_duration\", \"total_fixation_duration\", \"client_total_fixation_duration\", \"sample_size\"]]\n",
    "result_df\n",
    "result_df.to_excel(f\"./{client.lower()}_tier_{tier}_example_report.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tiered data\n",
    "df_1 = pd.read_excel(f\"./{client.lower()}_tier_1_example_report.xlsx\")\n",
    "df_1[\"tier\"] = 1\n",
    "df_2 = pd.read_excel(f\"./{client.lower()}_tier_2_example_report.xlsx\")\n",
    "df_2[\"tier\"] = 2\n",
    "df_3 = pd.read_excel(f\"./{client.lower()}_tier_3_example_report.xlsx\")\n",
    "df_3[\"tier\"] = 3\n",
    "all_df = [df_1, df_2, df_3]\n",
    "combined_client_df = pd.concat(all_df)\n",
    "columns = list(df_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9aa8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_based_on_tier(client_dfs):\n",
    "    new_df = pd.DataFrame(columns=columns)\n",
    "    for i, df in enumerate(client_dfs):\n",
    "        for index, row in df.iterrows():\n",
    "            if row.tier == 1:\n",
    "                if row.sample_size in (\"high\", \"medium\"):\n",
    "                    new_df = new_df.append(row)\n",
    "            elif row.tier == 2:\n",
    "                if new_df[new_df[\"hostname\"] == row.hostname][\"hostname\"].count() == 0 and row.tobii_imps >= 10:\n",
    "                    if row.sample_size == \"high\":\n",
    "                        # Degrade sample_size if lower tier\n",
    "                        row.sample_size = \"medium\"\n",
    "                        new_df = new_df.append(row)\n",
    "                    elif row.sample_size == \"medium\":\n",
    "                        new_row = combined_client_df[(combined_client_df[\"tier\"] == 3) & (combined_client_df[\"hostname\"] == row.hostname)]\n",
    "                        new_row.sample_size = \"medium\"\n",
    "                        new_row[\"client_fixations\"] = (\n",
    "                            np.floor(row[\"client_fixations\"] * 0.25 + new_row[\"client_fixations\"].sum() * 0.75)\n",
    "                        )\n",
    "                        new_df = new_df.append(new_row)\n",
    "                    else:\n",
    "                        new_row = combined_client_df[(combined_client_df[\"tier\"] == 3) & (combined_client_df[\"hostname\"] == row.hostname)]\n",
    "                        new_row.sample_size = \"medium\"\n",
    "                        new_row[\"client_fixations\"] = (\n",
    "                            np.floor(row[\"client_fixations\"] * 0.15 + new_row[\"client_fixations\"].sum() * 0.85)\n",
    "                        )\n",
    "                        new_df = new_df.append(new_row)\n",
    "            elif row.tier == 3:\n",
    "                if new_df[new_df[\"hostname\"] == row.hostname][\"hostname\"].count() == 0:\n",
    "                    row[\"sample_size\"] = \"low\"\n",
    "                    new_df = new_df.append(row)\n",
    "    return new_df\n",
    "\n",
    "final_client_df = get_data_based_on_tier(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce976ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_math(row, arg1, arg2):\n",
    "    try:\n",
    "        return round(row[f\"{arg1}\"] / row[f\"{arg2}\"] * 100, 2)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "final_client_df[\"client_Inview Ratio\"] = final_client_df.apply(lambda x: do_math(x, \"client_inview\", \"client_imps\"), axis=1)\n",
    "final_client_df[\"client_Fixation/Inview Ratio\"] = final_client_df.apply(lambda x: do_math(x, \"client_fixations\", \"client_inview\"), axis=1)\n",
    "final_client_df[\"tobii_Fixation/Inview Ratio\"] = final_client_df.apply(lambda x: do_math(x, \"tobii_fixations\", \"tobii_inview\"), axis=1)\n",
    "final_client_df[\"client_fixation/impression_ratio\"] = final_client_df.apply(lambda x: do_math(x, \"client_fixations\", \"client_imps\"), axis=1)\n",
    "final_client_df[\"Client Total Fixation Duration\"] = final_client_df[\"average_fixation_duration\"] * final_client_df[\"client_fixations\"]\n",
    "final_client_df = final_client_df[[\"hostname\", \"client_imps\", \"client_fixations\", \"tobii_fixation/impression_ratio\", \"client_inview\", \"client_Inview Ratio\", \"client_Fixation/Inview Ratio\", \"tobii_Fixation/Inview Ratio\", \"tobii_inview/impression_ratio\", \"Client Total Fixation Duration\", \"total_fixation_duration\", \"average_fixation_duration\", \"sample_size\", \"tier\"]]\n",
    "final_client_df = final_client_df.rename(\n",
    "    columns={\n",
    "        \"client_imps\": \"Impressions\", \n",
    "        \"client_fixations\": \"Fixations\",\n",
    "        \"client_inview\": \"Inviews\",\n",
    "        \"client_Inview Ratio\": \"Inview Ratio\",\n",
    "        \"tobii_Fixation/Inview Ratio\": \"Fixation/Tobii Inview Ratio\",\n",
    "        \"client_Fixation/Inview Ratio\": \"Fixation/Inview Ratio\",\n",
    "        \"average_fixation_duration\": \"Average Fixation Duration\",\n",
    "        \"total_fixation_duration\": \"Total Fixation Duration\",\n",
    "        \"sample_size\": \"Sample Size\"\n",
    "    }\n",
    ")\n",
    "final_client_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ec9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_client_df = final_client_df[[\"hostname\", \"Impressions\", \"Inviews\", \"Fixations\", \"Fixation/Inview Ratio\", \"Average Fixation Duration\", \"Total Fixation Duration\", \"Client Total Fixation Duration\", \"Sample Size\"]]\n",
    "final_client_df = final_client_df.sort_values(by=[\"hostname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd73a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\"Tier 1\", \"Tier 2\", \"Tier 3\"]\n",
    "\n",
    "with pd.ExcelWriter(f\"./{client}_results_internal.xlsx\") as writer:\n",
    "    rows = 0\n",
    "    spaces = 0\n",
    "    for n, df in enumerate(all_df):\n",
    "        pd.Series(comments[n]).to_excel(writer, sheet_name=client.title(), index=False, header=False, startrow=rows + spaces)\n",
    "        df.to_excel(writer, client.title(), index=False, startrow=1 + rows + spaces)\n",
    "        rows += len(df) + 2\n",
    "        spaces += 2\n",
    "\n",
    "with pd.ExcelWriter(f\"./{client}_results.xlsx\") as writer:\n",
    "    for df in [final_client_df]:\n",
    "        df.to_excel(writer, sheet_name=client.title(), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
